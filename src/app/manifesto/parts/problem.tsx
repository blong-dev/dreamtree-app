export function ProblemContent() { // code_id:906
  return (
    <>
      <h2>The Stakes</h2>

      <p>
        You cannot revolt against an algorithm you don&apos;t understand. You cannot
        debate a neural network that governs credit access, employment visibility,
        or political discourse.
      </p>

      <p>
        This is what Hannah Arendt called the banality of evil: not monstrous
        intention, but thoughtless administration of harm through impersonal
        systems. The data center has no conscience. The recommendation engine has
        no ethics. They optimize for engagement, for retention, for conversion. The
        human costs are externalities, if they are measured at all.
      </p>

      <p>
        If tyranny today is informational, then resistance must be epistemic. A
        battle for clarity, participation, and conscience. This document is one
        small act in that battle.
      </p>

      <p>
        What follows is not a complaint. It is a diagnosis. Four crises, one cause,
        and a question that demands an answer.
      </p>

      <hr />

      <h2>The Single Failure</h2>

      <p>Four crises dominate the digital economy. They appear unrelated. They are not.</p>

      <p>
        <strong>The exhaustion of attention.</strong> For two decades, platforms
        have harvested behavioral data, packaged predictive insights, and sold them
        to advertisers. Shoshana Zuboff named this system precisely:{' '}
        <em>surveillance capitalism</em>—the unilateral claiming of human experience
        as free raw material for behavioral prediction. Global advertising
        expenditure now exceeds $1.1 trillion annually, with over 73% flowing
        through digital channels. The efficiency gains have plateaued. The trust is
        gone. The costs are not only economic: the U.S. Surgeon General&apos;s 2023
        advisory found that adolescents spending more than three hours daily on
        social media face double the risk of depression and anxiety—and the average
        teenager now spends 3.5 hours per day. What once appeared to be an engine of
        innovation now resembles a strip mine: initial yields were high, but the
        seams are running dry, and the human wreckage is mounting.
      </p>

      <p>
        <strong>The anxiety of displacement.</strong> Artificial intelligence has
        shifted from optimism to dread. Unlike previous technological revolutions,
        AI encroaches upon cognitive and creative domains once thought uniquely
        human. The International Monetary Fund estimates 40% of global employment is
        exposed to AI-driven automation. The OECD calculates 14-30% of jobs in
        member states face high risk. 71% of Americans expect AI to permanently
        reduce jobs. The gap between experts and the public is striking: 73% of AI
        researchers are optimistic about AI&apos;s impact on work, compared to just
        23% of the general population. The promise was productivity. The reality is
        what Guy Standing calls the precariat: a class defined by instability,
        eroded trust in institutions, and mounting anxiety about the future.
      </p>

      <p>
        <strong>The extraction gap.</strong> This started in the 1970s. From 1948 to
        1979, productivity and hourly compensation grew together—about 2% annually
        each. After 1979, they diverged: productivity rose 73.9% while typical
        worker compensation grew only 17.1%. The digital economy widened the gap
        further. Every search query trained a model. Every photo tagged improved
        facial recognition. Every creative work scraped without consent now powers
        generative AI. Most of the humans who generate this value received none of
        the returns. Their contributions were externalities, not assets.
      </p>

      <p>
        <strong>The trust crisis.</strong> Employers face unverifiable credentials.
        Institutions cannot prove outcomes. 79% of Americans do not trust companies
        to use AI responsibly. AI developers face litigation for training on
        unlicensed data. The New York Times sued OpenAI. Getty Images pursued
        Stability AI in the UK, where the High Court largely rejected their
        infringement claims—a reminder that litigation outcomes are uncertain.
        Anthropic settled for $1.5 billion: $3,000 per book for an estimated 500,000
        works, with a requirement to destroy the pirated libraries. The EU AI Act
        now requires provenance disclosure.
      </p>

      <p>
        Four crises. One cause:{' '}
        <strong>
          the systematic failure to recognize, verify, and fairly reward human
          contributions in a digital economy increasingly shaped by AI.
        </strong>
      </p>

      <p>
        The attention economy did not merely exhaust itself. It revealed a deeper
        pathology: modern capitalism rewards extraction over creation. Personal
        experiences become behavioral data. Data becomes prediction. Prediction
        becomes revenue. The humans who generate the raw material receive nothing.
        This is not an accident. It is the architecture.
      </p>

      <hr />

      <h2>The Counterarguments</h2>

      <p>A fair reader will object.</p>

      <p>
        <em>Has the attention economy not also created value?</em> Yes. Search
        engines organize human knowledge. Social platforms enable connection across
        distance. Free services subsidized by advertising have genuine utility.
        Consumer surplus from digital goods is enormous but unmeasured in GDP. The
        critique is not that platforms create no value. It is that the distribution
        of value is systematically misaligned.
      </p>

      <p>
        <em>Is AI displacement not overstated by historical precedent?</em> Perhaps.
        Agricultural mechanization displaced farmers. Manufacturing automation
        displaced factory workers. In both cases, labor markets eventually adapted.
        The &quot;lump of labor fallacy&quot; suggests that automation creates new
        work even as it destroys old work. But the speed of AI advancement, and its
        encroachment on cognitive tasks, may outpace adaptation. We do not know.
        What we know is that the anxiety is real, and institutions have no good
        answer for it.
      </p>

      <p>
        <em>Are credentials truly unverifiable, or merely imperfect?</em> Degrees
        and certifications provide some signal. LinkedIn endorsements provide some
        reputation. The system functions, imperfectly. But &quot;functions
        imperfectly&quot; is not the same as &quot;works well.&quot; Skilled
        individuals without formal credentials remain invisible. Resume inflation is
        rampant. Workplace surveillance expands because employers cannot otherwise
        measure contribution. The trust gap is real.
      </p>

      <p>
        These objections are serious. They do not, however, refute the diagnosis.
        They qualify it. The attention economy created value and distributed it
        unfairly. AI may or may not cause mass unemployment, but it is certainly
        causing mass anxiety. Credentials work, sort of, for some people. None of
        this is good enough.
      </p>

      <hr />

      <h2>The Convergence</h2>

      <p>The dynamics are converging:</p>

      <ul>
        <li>Advertising markets are saturated; returns are diminishing.</li>
        <li>AI disruption is accelerating; public anxiety is mounting.</li>
        <li>Regulators, courts, and markets are demanding attribution and provenance.</li>
        <li>Workers, learners, and creators are asking: <em>Where is my share?</em></li>
      </ul>

      <p>
        These are not separate problems. They are manifestations of a single
        structural failure:{' '}
        <strong>
          the absence of infrastructure that connects human contributions to
          economic participation.
        </strong>
      </p>

      <p>
        The digital economy was built on extraction because extraction was easy.
        Attention could be harvested without consent. Data could be scraped without
        attribution. Value could be captured without compensation. The architecture
        permitted it, and so it happened.
      </p>

      <p>
        The question is not whether this architecture is broken. It is. The question
        is what replaces it.
      </p>

      <hr />

      <h2>The Question</h2>

      <p>
        The philosopher Jacques Ellul warned that once &quot;technique&quot; becomes
        society&apos;s highest value, efficiency replaces ethics. Moral questions
        become technical problems to be optimized, not human dilemmas to be wrestled
        with. That is the birth of soft tyranny: not through hatred, but through the
        quiet displacement of conscience by convenience.
      </p>

      <p>
        Nietzsche warned that those who cannot imagine alternative futures become
        slaves to history&apos;s &quot;last men&quot; content, comfortable, and
        spiritually vacant.
      </p>

      <p>
        The antidote is not despair. It is moral imagination: the capacity to
        envision futures that value depth over dominance, meaning over metrics.
      </p>

      <p>
        The question is not whether change is coming. The question is who will shape
        it, and toward what ends.
      </p>
    </>
  );
}
